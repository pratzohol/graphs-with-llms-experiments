{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from models.gnn import GNN\n",
    "from models.mlp import MLP\n",
    "from utils.dataloader import GetDataloader\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import os.path as osp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, dataset_name=\"cora\", sentence_encoder=\"ST\", model_type=\"mlp\", device=0, state_dict_path=\"./state_dicts\"):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.model_type = model_type.lower()\n",
    "        self.device = \"cpu\" if device==123 else f\"cuda:{device}\"\n",
    "\n",
    "        self.state_dict_path = osp.join(state_dict_path, f\"{self.dataset_name}_{self.sentence_encoder}\", f\"{model_type}\")\n",
    "        if not osp.exists(self.state_dict_path):\n",
    "            os.makedirs(self.state_dict_path)\n",
    "\n",
    "        dataloader = GetDataloader(dataset_name=self.dataset_name, sentence_encoder=self.sentence_encoder, device=self.device)\n",
    "        self.data = dataloader.get_data()\n",
    "        self.num_classes = len(self.data.y.squeeze().unique())\n",
    "\n",
    "        if self.model_type == \"mlp\":\n",
    "            self.model = MLP(num_classes=self.num_classes)\n",
    "        elif self.model_type in [\"gcn\", \"gat\", \"sage\", \"graphsage\"]:\n",
    "            self.model = GNN(name=self.model_type, num_classes=self.num_classes)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.data = self.data.to(device=self.device)\n",
    "        self.model = self.model.to(device=self.device)\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    def train(self, mask_idx):\n",
    "        best_val_acc = 0\n",
    "\n",
    "        # total of 10 training masks are present for each dataset\n",
    "        for e in range(1, 201):\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            out = self.model(self.data)\n",
    "            train_pred = out.argmax(dim=1)\n",
    "\n",
    "            train_ypred = train_pred[self.data.train_masks[mask_idx]]\n",
    "            train_ytrue = self.data.y[self.data.train_masks[mask_idx]]\n",
    "            train_correct = (train_ypred == train_ytrue).sum()\n",
    "\n",
    "            train_acc = int(train_correct) / int(self.data.train_masks[mask_idx].sum())\n",
    "            train_loss = F.cross_entropy(out[self.data.train_masks[mask_idx]], train_ytrue)\n",
    "\n",
    "            if e % 10 == 0:\n",
    "                val_ypred = train_pred[self.data.val_masks[mask_idx]]\n",
    "                val_ytrue = self.data.y[self.data.val_masks[mask_idx]]\n",
    "                val_correct = (val_ypred == val_ytrue).sum()\n",
    "\n",
    "                val_acc = int(val_correct) / int(self.data.val_masks[mask_idx].sum())\n",
    "                val_loss = F.cross_entropy(out[self.data.val_masks[mask_idx]], val_ytrue)\n",
    "\n",
    "                # print(f\"Epoch {e} => Train Accuracy : {train_acc} | Train Loss : {train_loss}\")\n",
    "                # print(f\"Validation Accuracy : {val_acc} | Validation Loss : {val_loss}\")\n",
    "\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "\n",
    "                    save_path = osp.join(self.state_dict_path, f\"Mask_{mask_idx}_best_state_dict.pt\")\n",
    "                    if osp.exists(save_path):\n",
    "                        os.remove(save_path)\n",
    "\n",
    "                    model_info = {\"state_dict\" : self.model.state_dict(),\n",
    "                                    \"optimizer_state_dict\" : self.optimizer.state_dict(),\n",
    "                                    \"val_accuracy\" : best_val_acc,\n",
    "                                    \"val_loss\" : val_loss}\n",
    "\n",
    "                    torch.save(model_info, save_path)\n",
    "\n",
    "            train_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            out = self.model(self.data)\n",
    "            pred = out.argmax(dim=1)\n",
    "\n",
    "            ypred = pred[self.data.test_masks[mask_idx]]\n",
    "            ytrue = self.data.y[self.data.test_masks[mask_idx]]\n",
    "            test_correct = (ypred == ytrue).sum()\n",
    "\n",
    "            test_acc = int(test_correct) / int(self.data.test_masks[mask_idx].sum())\n",
    "            test_loss = float(F.cross_entropy(out[self.data.test_masks[mask_idx]], ytrue))\n",
    "\n",
    "        return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [13:25<00:00, 201.38s/it]\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"cora_ST\", \"cora_roberta\", \"pubmed_ST\", \"pubmed_roberta\"]\n",
    "model_types = [\"mlp\", \"gcn\", \"gat\", \"sage\"]\n",
    "\n",
    "final_results = dict.fromkeys(datasets)\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    dataset_name = dataset.split(\"_\")[0]\n",
    "    sent_encoder = dataset.split(\"_\")[1]\n",
    "\n",
    "    results = dict.fromkeys(model_types)\n",
    "\n",
    "    for model_t in model_types:\n",
    "        test_acc = np.zeros(10)\n",
    "        test_losses = np.zeros(10)\n",
    "\n",
    "        for idx in range(10):\n",
    "            trainer = Trainer(dataset_name=dataset_name, sentence_encoder=sent_encoder, model_type=model_t, device=0)\n",
    "            acc, loss = trainer.train(idx)\n",
    "\n",
    "            test_acc[idx] = acc\n",
    "            test_losses[idx] = loss\n",
    "\n",
    "        avg_test_acc = test_acc.mean()\n",
    "        std_test_acc = test_acc.std()\n",
    "\n",
    "        avg_test_loss = test_losses.mean()\n",
    "        std_test_loss = test_losses.std()\n",
    "\n",
    "        results[model_t] = {\"Test Accuracy (avg)\" : avg_test_acc,\n",
    "                            \"Test Accuracy (std)\" : std_test_acc,\n",
    "                            \"Test Loss (avg)\" : avg_test_loss,\n",
    "                            \"Test Loss (std)\" : std_test_loss}\n",
    "\n",
    "    final_results[dataset] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test Accuracy (avg)</th>\n",
       "      <th>Test Accuracy (std)</th>\n",
       "      <th>Test Loss (avg)</th>\n",
       "      <th>Test Loss (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">cora_ST</th>\n",
       "      <th>mlp</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>1.378926</td>\n",
       "      <td>0.123853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcn</th>\n",
       "      <td>0.806093</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.618293</td>\n",
       "      <td>0.027128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gat</th>\n",
       "      <td>0.796422</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.639135</td>\n",
       "      <td>0.039659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>0.790232</td>\n",
       "      <td>0.011012</td>\n",
       "      <td>1.322649</td>\n",
       "      <td>0.011970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">cora_roberta</th>\n",
       "      <th>mlp</th>\n",
       "      <td>0.484623</td>\n",
       "      <td>0.026222</td>\n",
       "      <td>2.717465</td>\n",
       "      <td>0.260291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcn</th>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.899008</td>\n",
       "      <td>0.055134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gat</th>\n",
       "      <td>0.717892</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>1.060394</td>\n",
       "      <td>0.103915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>0.729014</td>\n",
       "      <td>0.020994</td>\n",
       "      <td>1.390071</td>\n",
       "      <td>0.017474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">pubmed_ST</th>\n",
       "      <th>mlp</th>\n",
       "      <td>0.717910</td>\n",
       "      <td>0.017322</td>\n",
       "      <td>1.028179</td>\n",
       "      <td>0.105397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcn</th>\n",
       "      <td>0.783071</td>\n",
       "      <td>0.014785</td>\n",
       "      <td>0.556836</td>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gat</th>\n",
       "      <td>0.770512</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.632819</td>\n",
       "      <td>0.046770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>0.732098</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.756743</td>\n",
       "      <td>0.016917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">pubmed_roberta</th>\n",
       "      <th>mlp</th>\n",
       "      <td>0.625980</td>\n",
       "      <td>0.020894</td>\n",
       "      <td>2.190036</td>\n",
       "      <td>0.187592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcn</th>\n",
       "      <td>0.750890</td>\n",
       "      <td>0.021671</td>\n",
       "      <td>0.905303</td>\n",
       "      <td>0.101393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gat</th>\n",
       "      <td>0.723036</td>\n",
       "      <td>0.025905</td>\n",
       "      <td>1.107729</td>\n",
       "      <td>0.186055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>0.700726</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>0.795258</td>\n",
       "      <td>0.026426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Test Accuracy (avg)  Test Accuracy (std)  \\\n",
       "cora_ST        mlp              0.640377             0.024404   \n",
       "               gcn              0.806093             0.009473   \n",
       "               gat              0.796422             0.007839   \n",
       "               sage             0.790232             0.011012   \n",
       "cora_roberta   mlp              0.484623             0.026222   \n",
       "               gcn              0.743182             0.016231   \n",
       "               gat              0.717892             0.014368   \n",
       "               sage             0.729014             0.020994   \n",
       "pubmed_ST      mlp              0.717910             0.017322   \n",
       "               gcn              0.783071             0.014785   \n",
       "               gat              0.770512             0.017548   \n",
       "               sage             0.732098             0.017074   \n",
       "pubmed_roberta mlp              0.625980             0.020894   \n",
       "               gcn              0.750890             0.021671   \n",
       "               gat              0.723036             0.025905   \n",
       "               sage             0.700726             0.022902   \n",
       "\n",
       "                     Test Loss (avg)  Test Loss (std)  \n",
       "cora_ST        mlp          1.378926         0.123853  \n",
       "               gcn          0.618293         0.027128  \n",
       "               gat          0.639135         0.039659  \n",
       "               sage         1.322649         0.011970  \n",
       "cora_roberta   mlp          2.717465         0.260291  \n",
       "               gcn          0.899008         0.055134  \n",
       "               gat          1.060394         0.103915  \n",
       "               sage         1.390071         0.017474  \n",
       "pubmed_ST      mlp          1.028179         0.105397  \n",
       "               gcn          0.556836         0.032271  \n",
       "               gat          0.632819         0.046770  \n",
       "               sage         0.756743         0.016917  \n",
       "pubmed_roberta mlp          2.190036         0.187592  \n",
       "               gcn          0.905303         0.101393  \n",
       "               gat          1.107729         0.186055  \n",
       "               sage         0.795258         0.026426  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_ = {(i, j) : final_results[i][j] for i in final_results.keys() for j in final_results[i].keys()}\n",
    "df = pd.DataFrame.from_dict(final_results_, orient=\"index\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
