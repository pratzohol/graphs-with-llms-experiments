{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch_geometric\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "from encoder import SentenceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pubmed dataset\n",
    "data_root = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubmedPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, dataRoot=\"../data\", custom_dataRoot=\"../custom_data\", sentence_encoder=None, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_root = dataRoot\n",
    "        self.custom_data_root = custom_dataRoot\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.custom_data_dir = osp.join(\n",
    "            self.custom_data_root, f\"pubmed_{self.sentence_encoder.name}\")\n",
    "\n",
    "        if not osp.exists(self.custom_data_dir):\n",
    "            os.makedirs(self.custom_data_dir)\n",
    "\n",
    "        super().__init__(self.custom_data_dir, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\", \"texts.pkl\"]\n",
    "\n",
    "    def text_to_embed(self, texts):\n",
    "        if self.sentence_encoder is None:\n",
    "            raise NotImplementedError(\"Sentence Encoder is not passed\")\n",
    "        if texts is None:\n",
    "            return None\n",
    "        else:\n",
    "            # returns to self.device\n",
    "            return self.sentence_encoder.encode(texts)\n",
    "\n",
    "    def encode_texts(self, texts):\n",
    "        if isinstance(texts[0], str):\n",
    "            return self.text_to_embed(texts)\n",
    "        return [self.text_to_embed(t) for t in texts]\n",
    "\n",
    "    def generate_custom_data(self):\n",
    "        # Load the raw pubmed dataset\n",
    "        data_path = osp.join(self.data_root, \"pubmed\", \"pubmed.pt\")\n",
    "        raw_pubmed_data = torch.load(data_path)\n",
    "\n",
    "        texts = raw_pubmed_data.raw_text\n",
    "        label_names = raw_pubmed_data.label_names\n",
    "\n",
    "\n",
    "        # Label and label description\n",
    "        category_desc = pd.read_csv(osp.join(self.data_root, \"pubmed\", \"categories.csv\"), sep=\",\", header=None).values\n",
    "\n",
    "        # Sort the label desc by the order of label_names\n",
    "        ordered_desc = []\n",
    "        for i, label in enumerate(label_names):\n",
    "            true_ind = (label == category_desc[:, 0])\n",
    "            ordered_desc.append((label, category_desc[true_ind, 1][0]))\n",
    "\n",
    "        # Prompts for nodes/edges in original graph (can be changed accordingly)\n",
    "        node_texts = [\"Feature Node.\\n Paper Title and abstract: \" + t for t in texts]\n",
    "        edge_text = [\"Feature Edge.\\n Connected papers are cited together by other papers.\"]\n",
    "\n",
    "        # Node classification : Prompts for prompt node and label node (can be changed accordingly)\n",
    "        prompt_node_text = [\"Prompt Node.\\n Node Classification on the paper's category\"]\n",
    "        label_texts = [\"Prompt Node.\\n Literature Category and Description: \" + desc[0] + \" + \" + desc[1] for desc in ordered_desc]\n",
    "\n",
    "        # Link prediction : Prompts for prompt node and edge labels (can be changed accordingly)\n",
    "        prompt_node_edge_text = [\"Prompt Node.\\n Link Prediction on the papers that are cited together\"]\n",
    "        edge_label_text = [\"Prompt Node.\\n Two papers have co-citation\",\n",
    "                           \"Prompt Node.\\n Two papers do not have co-citation\"]\n",
    "\n",
    "        # Prompt for edge b/w prompt node and labels (can be changed accordingly)\n",
    "        prompt_edge_text = [\"Prompt Edge.\"]\n",
    "\n",
    "        return raw_pubmed_data, [node_texts, label_texts, edge_text, prompt_node_edge_text, prompt_node_text, prompt_edge_text, edge_label_text]\n",
    "\n",
    "    def process(self):\n",
    "        # raw pubmed dataset is not in any library, so we process and load it manually in self.generate_custom_data()\n",
    "        pubmed_data_list, texts = self.generate_custom_data()\n",
    "        texts_embed = self.encode_texts(texts)\n",
    "\n",
    "        torch.save(texts, self.processed_paths[1])\n",
    "\n",
    "        pubmed_data_list.x_text_feat = texts_embed[0]\n",
    "        pubmed_data_list.label_text_feat = texts_embed[1]\n",
    "        pubmed_data_list.edge_text_feat = texts_embed[2]\n",
    "        pubmed_data_list.prompt_text_edge_feat = texts_embed[3]\n",
    "        pubmed_data_list.prompt_text_feat = texts_embed[4]\n",
    "        pubmed_data_list.prompt_edge_feat = texts_embed[5]\n",
    "        pubmed_data_list.edge_label_feat = texts_embed[6]\n",
    "\n",
    "        # Pass the data_list as a list\n",
    "        data, slices = self.collate([pubmed_data_list])\n",
    "\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        print(\"Pubmed is processed. Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder = SentenceEncoder(\"ST\", device=2)\n",
    "custom_pubmed = PubmedPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder2 = SentenceEncoder(\"roberta\", device=2)\n",
    "custom_pubmed2 = PubmedPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubmedPyGDataset()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[19717, 384], edge_index=[2, 88670], y=[19717], train_masks=[10], val_masks=[10], test_masks=[10], label_names=[3], category_names=[19717], raw_text=[19717], x_text_feat=[19717, 768], label_text_feat=[3, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed = custom_pubmed._data\n",
    "pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed.train_masks # it contains 10 different train masks (we will take avg of the accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
