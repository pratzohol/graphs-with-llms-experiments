{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch_geometric\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "from encoder import SentenceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the cora dataset\n",
    "data_root = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoraPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, dataRoot=\"../data\", custom_dataRoot=\"../custom_data\", sentence_encoder=None, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_root = dataRoot\n",
    "        self.custom_data_root = custom_dataRoot\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.custom_data_dir = osp.join(self.custom_data_root, f\"cora_{self.sentence_encoder.name}\")\n",
    "\n",
    "        if not osp.exists(self.custom_data_dir):\n",
    "            os.makedirs(self.custom_data_dir)\n",
    "\n",
    "        super().__init__(self.custom_data_dir, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\", \"texts.pkl\"]\n",
    "\n",
    "    def text_to_embed(self, texts):\n",
    "        if self.sentence_encoder is None:\n",
    "            raise NotImplementedError(\"Sentence Encoder is not passed\")\n",
    "        if texts is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.sentence_encoder.encode(texts)  # returns to self.device\n",
    "\n",
    "    def encode_texts(self, texts):\n",
    "        if isinstance(texts[0], str):\n",
    "            return self.text_to_embed(texts)\n",
    "        return [self.text_to_embed(t) for t in texts]\n",
    "\n",
    "    def generate_custom_data(self):\n",
    "        # Load the raw cora dataset\n",
    "        data_path = osp.join(self.data_root, \"cora\", \"cora.pt\")\n",
    "        raw_cora_data = torch.load(data_path)\n",
    "\n",
    "        texts = raw_cora_data.raw_text\n",
    "        label_names = raw_cora_data.label_names\n",
    "\n",
    "\n",
    "        # Label and label description\n",
    "        category_desc = pd.read_csv(osp.join(self.data_root, \"cora\", \"categories.csv\"), sep=\",\").values\n",
    "\n",
    "        # Sort the label desc by the order of label_names\n",
    "        ordered_desc = []\n",
    "        for i, label in enumerate(label_names):\n",
    "            true_ind = (label == category_desc[:, 0])\n",
    "            ordered_desc.append((label, category_desc[true_ind, 1][0]))\n",
    "\n",
    "        # Prompts for nodes/edges in original graph (can be changed accordingly)\n",
    "        node_texts = [\"Feature Node.\\n Paper Title and abstract: \" + t for t in texts]\n",
    "        edge_text = [\"Feature Edge.\\n Connected papers are cited together by other papers.\"]\n",
    "\n",
    "        # Node classification : Prompts for prompt node and label node (can be changed accordingly)\n",
    "        prompt_node_text = [\"Prompt Node.\\n Node Classification on the paper's category\"]\n",
    "        label_texts = [\"Prompt Node.\\n Literature Category and Description: \" + desc[0] + \" + \" + desc[1] for desc in ordered_desc]\n",
    "\n",
    "        # Link prediction : Prompts for prompt node and edge labels (can be changed accordingly)\n",
    "        prompt_node_edge_text = [\"Prompt Node.\\n Link Prediction on the papers that are cited together\"]\n",
    "        edge_label_text = [\"Prompt Node.\\n Two papers have co-citation\",\n",
    "                           \"Prompt Node.\\n Two papers do not have co-citation\"]\n",
    "\n",
    "        # Prompt for edge b/w prompt node and labels (can be changed accordingly)\n",
    "        prompt_edge_text = [\"Prompt Edge.\"]\n",
    "\n",
    "        return raw_cora_data, [node_texts, label_texts, edge_text, prompt_node_edge_text, prompt_node_text, prompt_edge_text, edge_label_text]\n",
    "\n",
    "    def process(self):\n",
    "        # raw cora dataset is not in any library, so we process and load it manually in self.generate_custom_data()\n",
    "        cora_data_list, texts = self.generate_custom_data()\n",
    "        texts_embed = self.encode_texts(texts)\n",
    "\n",
    "        torch.save(texts, self.processed_paths[1])\n",
    "\n",
    "        cora_data_list.x_text_feat = texts_embed[0]\n",
    "        cora_data_list.label_text_feat = texts_embed[1]\n",
    "        cora_data_list.edge_text_feat = texts_embed[2]\n",
    "        cora_data_list.prompt_text_edge_feat = texts_embed[3]\n",
    "        cora_data_list.prompt_text_feat = texts_embed[4]\n",
    "        cora_data_list.prompt_edge_feat = texts_embed[5]\n",
    "        cora_data_list.edge_label_feat = texts_embed[6]\n",
    "\n",
    "        # Pass the data_list as a list\n",
    "        data, slices = self.collate([cora_data_list])\n",
    "\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        print(\"Cora is processed. Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder = SentenceEncoder(\"ST\", root=\"../lang_models\", device=2)\n",
    "custom_cora = CoraPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder2 = SentenceEncoder(\"roberta\", root=\"../lang_models\", device=2)\n",
    "custom_cora2 = CoraPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(raw_text=[2708], y=[2708], label_names=[7], edge_index=[2, 10858], train_masks=[10], val_masks=[10], test_masks=[10], x=[2708, 384], category_names=[2708], x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora = custom_cora._data\n",
    "cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([False,  True,  True,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False,  True,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora.train_masks # it contains 10 different train masks (we will take avg of the accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 0, 5, 4, 3, 1, 0, 4, 6, 2, 2, 6, 2, 1, 3, 0, 4, 5, 5, 5, 1, 0,\n",
       "        1, 1, 3, 4, 4, 0, 3, 2, 2, 1, 2, 1, 0, 4, 6, 3, 6, 5, 6, 3, 2, 3, 0, 2,\n",
       "        6, 3, 3, 1, 0, 5, 6, 1, 4, 0, 1, 1, 5, 6, 4, 2, 5, 3, 4, 2, 0, 5, 4, 2,\n",
       "        1, 1, 5, 6, 5, 0, 2, 6, 4, 5, 1, 2, 0, 5, 2, 1, 3, 0, 4, 0, 0, 5, 4, 6,\n",
       "        6, 6, 3, 3, 4, 3, 3, 3, 2, 5, 5, 6, 5, 6, 2, 3, 6, 3, 6, 5, 6, 1, 0, 6,\n",
       "        4, 6, 3, 4, 4, 1, 0, 4, 1, 0, 2, 2, 5, 4, 3, 4, 0, 5, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cora.y[custom_cora.train_masks[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(raw_text=[2708], y=[2708], label_names=[7], edge_index=[2, 10858], train_masks=[10], val_masks=[10], test_masks=[10], x=[2708, 384], category_names=[2708], x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cora._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(raw_text=[1], y=[2708], label_names=[1], edge_index=[2, 10858], train_masks=[10], val_masks=[10], test_masks=[10], x=[2708, 384], category_names=[1], x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], batch=[2708], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dl = DataLoader(custom_cora, batch_size=12)\n",
    "\n",
    "for batch in dl:\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
