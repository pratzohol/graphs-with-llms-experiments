{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prateek/graphs-with-llms-experiments/utils_data', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python310.zip', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python3.10', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python3.10/lib-dynload', '', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python3.10/site-packages', '/home/prateek/graphs-with-llms-experiments']\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch_geometric\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from datasets import load_dataset\n",
    "\n",
    "sys.path.append(osp.abspath(\"..\"))\n",
    "print(sys.path)\n",
    "\n",
    "from utils.encoder import SentenceEncoder\n",
    "from utils_data.custom_pyg import CustomPygDataset\n",
    "from utils.dataloader import GetDataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the ogbn-products dataset\n",
    "data_root = \"../data\"\n",
    "products = PygNodePropPredDataset(name='ogbn-products', root=data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=2449029, edge_index=[2, 123718280], x=[2449029, 100], y=[2449029, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = products[0]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,  152857,       0,  ..., 2449028,   53324, 2449028],\n",
       "        [ 152857,       0,   32104,  ...,  162836, 2449028,   53324]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ei = dataset.edge_index\n",
    "ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_feature(data_root):\n",
    "    nodeidx2asin = pd.read_csv(osp.join(data_root, \"ogbn_products/mapping/nodeidx2asin.csv.gz\"), index_col=\"node idx\")\n",
    "\n",
    "    raw_train = load_dataset(\"json\", data_files=osp.join(data_root, \"ogbn_products/Amazon-3M.raw/trn.json.gz\"))\n",
    "    raw_test = load_dataset(\"json\", data_files=osp.join(data_root, \"ogbn_products/Amazon-3M.raw/tst.json.gz\"))\n",
    "\n",
    "    raw_train_df = raw_train[\"train\"].to_pandas()\n",
    "    raw_test_df = raw_test[\"train\"].to_pandas()\n",
    "    raw_combined_df = pd.concat([raw_train_df, raw_test_df], ignore_index=True)\n",
    "\n",
    "    products_titdesc = pd.merge(nodeidx2asin, raw_combined_df, left_on=\"asin\", right_on=\"uid\")\n",
    "\n",
    "    # Prompt for the feature of nodes (can be changed accordingly)\n",
    "    node_feature_prompt = (\"Feature Node.\\n\"\n",
    "                           + \"Product Title and Description : \"\n",
    "                           + products_titdesc[\"title\"]\n",
    "                           + \" + \"\n",
    "                           + products_titdesc[\"content\"])\n",
    "\n",
    "    node_feature_prompt_list = node_feature_prompt.values\n",
    "    return node_feature_prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_feature(data_root):\n",
    "    label2cat = pd.read_csv(osp.join(data_root, \"ogbn_products/mapping/labelidx2productcategory.csv.gz\"), index_col=\"label idx\")\n",
    "\n",
    "    # Fixing few errors\n",
    "    label2cat.loc[24] = \"Label 25\"\n",
    "    label2cat.loc[45] = \"Furniture & Decor\"\n",
    "    label2cat.loc[46] = \"Label 47\" # replacing '#508510'\n",
    "\n",
    "    # Prompt for the label nodes (can be changed accordingly)\n",
    "    label_node_prompt = (\"Prompt Node.\\n\"\n",
    "                         + \"Product Category : \"\n",
    "                         + label2cat[\"product category\"])\n",
    "\n",
    "    label_node_prompt_list = label_node_prompt.values\n",
    "    return label_node_prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductsPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, dataRoot=\"../data\", custom_dataRoot=\"../custom_data\", sentence_encoder=None, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_root = dataRoot\n",
    "        self.custom_data_root = custom_dataRoot\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.custom_data_dir = osp.join(self.custom_data_root, f\"ogbn_products_{self.sentence_encoder.name}\")\n",
    "\n",
    "        if not osp.exists(self.custom_data_dir):\n",
    "            os.makedirs(self.custom_data_dir)\n",
    "\n",
    "        super().__init__(self.custom_data_dir, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\", \"texts.pkl\"]\n",
    "\n",
    "    def text_to_embed(self, texts):\n",
    "        if self.sentence_encoder is None:\n",
    "            raise NotImplementedError(\"Sentence Encoder is not passed\")\n",
    "        if texts is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.sentence_encoder.encode(texts) # returns to self.device\n",
    "\n",
    "    def encode_texts(self, texts):\n",
    "        if isinstance(texts[0], str):\n",
    "            return self.text_to_embed(texts)\n",
    "        return [self.text_to_embed(t) for t in texts]\n",
    "\n",
    "    def generate_custom_data(self):\n",
    "        node_texts = get_node_feature(self.data_root).tolist()\n",
    "        label_texts = get_label_feature(self.data_root).tolist()\n",
    "\n",
    "        # Prompt for prompt node/edge and edge texts (can be changed accordingly)\n",
    "        edge_texts = [\"Feature Edge.\\n Co-purchased. Two products were purchased together on Amazon\"]\n",
    "        prompt_texts = [\"Prompt Node.\\n Node Classification of Product Category\"]\n",
    "        prompt_edge_texts = [\"Prompt Edge.\"]\n",
    "\n",
    "        return [node_texts, label_texts, edge_texts, prompt_texts, prompt_edge_texts]\n",
    "\n",
    "    def process(self):\n",
    "        products_data = PygNodePropPredDataset(name=\"ogbn-products\", root=self.data_root)\n",
    "        products_data_list = products_data._data\n",
    "\n",
    "        products_data_list.edge_index = remove_self_loops(products_data_list.edge_index)[0] # remove self-loops from graph\n",
    "        products_data_list.y = products_data_list.y.squeeze()  # to flatten the y tensor\n",
    "\n",
    "        texts = self.generate_custom_data()\n",
    "        texts_embed = self.encode_texts(texts)\n",
    "\n",
    "        torch.save(texts, self.processed_paths[1])\n",
    "\n",
    "        products_data_list.x_text_feat = texts_embed[0] # node text feature\n",
    "        products_data_list.label_text_feat = texts_embed[1] # label text feature\n",
    "        products_data_list.edge_text_feat = texts_embed[2] # edge text feature\n",
    "        products_data_list.prompt_text_feat = texts_embed[3] # prompt node text feature\n",
    "        products_data_list.prompt_edge_feat = texts_embed[4] # prompt edge text feature\n",
    "\n",
    "        # get dataset split\n",
    "        split_idx = products_data.get_idx_split()\n",
    "        train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "\n",
    "        products_data_list.train_mask = train_idx\n",
    "        products_data_list.val_mask = valid_idx\n",
    "        products_data_list.test_mask = test_idx\n",
    "\n",
    "        data, slices = self.collate([products_data_list]) # Pass the data_list as a list\n",
    "\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        print(\"Products is processed. Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder = SentenceEncoder(root=\"../lang_models\", name=\"ST\", device=1)\n",
    "custom_products = ProductsPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder = SentenceEncoder(root=\"../lang_models\", name=\"roberta\", device=1)\n",
    "custom_products2 = ProductsPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=2449029, edge_index=[2, 123718024], x=[2449029, 100], y=[2449029], x_text_feat=[2449029, 768], label_text_feat=[47, 768], edge_text_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], train_mask=[196615], val_mask=[39323], test_mask=[2213091])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = custom_products._data\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes <class 'int'>\n",
      "edge_index <class 'torch.Tensor'>\n",
      "x <class 'torch.Tensor'>\n",
      "y <class 'torch.Tensor'>\n",
      "x_text_feat <class 'torch.Tensor'>\n",
      "label_text_feat <class 'torch.Tensor'>\n",
      "edge_text_feat <class 'torch.Tensor'>\n",
      "prompt_text_feat <class 'torch.Tensor'>\n",
      "prompt_edge_feat <class 'torch.Tensor'>\n",
      "train_mask <class 'torch.Tensor'>\n",
      "val_mask <class 'torch.Tensor'>\n",
      "test_mask <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for k, v in products:\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader, NodeLoader\n",
    "\n",
    "loader = None\n",
    "loader = NeighborLoader(data=products,\n",
    "                        num_neighbors=[-1, -1],\n",
    "                        input_nodes=torch.LongTensor([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(num_nodes=5740, edge_index=[2, 19354], x=[5740, 100], y=[5740], x_text_feat=[5740, 768], label_text_feat=[47, 768], edge_text_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], train_mask=[196615], val_mask=[39323], test_mask=[2213091], n_id=[5740], e_id=[19354], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1], batch_size=1)\n",
      "Data(num_nodes=8199, edge_index=[2, 14826], x=[8199, 100], y=[8199], x_text_feat=[8199, 768], label_text_feat=[47, 768], edge_text_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], train_mask=[196615], val_mask=[39323], test_mask=[2213091], n_id=[8199], e_id=[14826], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1], batch_size=1)\n",
      "Data(num_nodes=3504, edge_index=[2, 4549], x=[3504, 100], y=[3504], x_text_feat=[3504, 768], label_text_feat=[47, 768], edge_text_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], train_mask=[196615], val_mask=[39323], test_mask=[2213091], n_id=[3504], e_id=[4549], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1], batch_size=1)\n"
     ]
    }
   ],
   "source": [
    "for sg in loader:\n",
    "    print(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.is_directed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
