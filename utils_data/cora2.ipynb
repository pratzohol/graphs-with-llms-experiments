{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prateek/graphs-with-llms-experiments/utils_data', '/home/prateek/miniconda3/envs/torch_pyg/lib/python310.zip', '/home/prateek/miniconda3/envs/torch_pyg/lib/python3.10', '/home/prateek/miniconda3/envs/torch_pyg/lib/python3.10/lib-dynload', '', '/home/prateek/miniconda3/envs/torch_pyg/lib/python3.10/site-packages', '/home/prateek/graphs-with-llms-experiments']\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "sys.path.append(osp.abspath(\"..\"))\n",
    "print(sys.path)\n",
    "\n",
    "from utils.encoder import SentenceEncoder\n",
    "from utils_data.custom_pyg import CustomPygDataset\n",
    "from utils.dataloader import GetDataloader\n",
    "from utils_data.cora import CoraPyGDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 384], edge_index=[2, 10858], y=[2708], label_names=[7], num_nodes=2708, x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LMencoder = SentenceEncoder(\"ST\", root=\"../lang_models\", device=1)\n",
    "custom_cora = CoraPyGDataset(dataRoot=data_root, custom_dataRoot=\"../custom_data\", sentence_encoder=LMencoder)\n",
    "cora = custom_cora._data\n",
    "cora.to(\"cpu\")\n",
    "cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_name': 'Date -> 2024-02-03. Experiment_ST_evaluation-mode',\n",
       " 'dataRoot': '../data',\n",
       " 'custom_dataRoot': '../custom_data',\n",
       " 'dataset': 'cora',\n",
       " 'model_type': 'MLP',\n",
       " 'sentence_encoder': 'ST',\n",
       " 'encoder_path': '../lang_models',\n",
       " 'state_dict_path': './state_dicts',\n",
       " 'lr': 0.001,\n",
       " 'epochs': 200,\n",
       " 'batch_count': 5,\n",
       " 'batch_size': 2,\n",
       " 'weight_decay': 0.001,\n",
       " 'dropout': 0.3,\n",
       " 'seed': None,\n",
       " 'num_workers': 10,\n",
       " 'device': 'cuda:0',\n",
       " 'eval_only': False,\n",
       " 'n_way': 3,\n",
       " 'n_shot': 1,\n",
       " 'n_query': 1,\n",
       " 'num_neighbors': [-1],\n",
       " 'subgraph_type': 'directional'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from datetime import date\n",
    "\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    args = yaml.safe_load(f)\n",
    "\n",
    "args[\"device\"] = 'cpu' if args[\"device\"] == 123 else f\"cuda:{args['device']}\"\n",
    "args[\"exp_name\"] = f\"Date -> {date.today()}. Experiment_{args['sentence_encoder']}_{args['exp_name']}\"\n",
    "\n",
    "args[\"encoder_path\"] = '../lang_models'\n",
    "args[\"dataRoot\"] = '../data'\n",
    "args[\"custom_dataRoot\"] = '../custom_data'\n",
    "args[\"dataset\"] = \"cora\"\n",
    "args[\"batch_count\"] = 5\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.dataloader.GetDataloader at 0x7f581084feb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = GetDataloader(**args)\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{3: [505, 2033], 6: [1971, 772], 0: [1878, 1373]},\n",
       " {3: [2033, 2555], 2: [2150, 182], 0: [677, 322]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1 = next(iter(dl.trn_smplr))\n",
    "batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{3: [Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]),\n",
       "   Data(x=[4, 384], edge_index=[2, 3], y=[4], label_names=[7], num_nodes=4, x_text_feat=[4, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[4], val_mask=[4], test_mask=[4], n_id=[4], e_id=[3], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])],\n",
       "  6: [Data(x=[5, 384], edge_index=[2, 4], y=[5], label_names=[7], num_nodes=5, x_text_feat=[5, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[5], val_mask=[5], test_mask=[5], n_id=[5], e_id=[4], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]),\n",
       "   Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])],\n",
       "  0: [Data(x=[2, 384], edge_index=[2, 1], y=[2], label_names=[7], num_nodes=2, x_text_feat=[2, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2], val_mask=[2], test_mask=[2], n_id=[2], e_id=[1], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]),\n",
       "   Data(x=[4, 384], edge_index=[2, 3], y=[4], label_names=[7], num_nodes=4, x_text_feat=[4, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[4], val_mask=[4], test_mask=[4], n_id=[4], e_id=[3], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])]},\n",
       " {3: [Data(x=[4, 384], edge_index=[2, 3], y=[4], label_names=[7], num_nodes=4, x_text_feat=[4, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[4], val_mask=[4], test_mask=[4], n_id=[4], e_id=[3], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]),\n",
       "   Data(x=[5, 384], edge_index=[2, 4], y=[5], label_names=[7], num_nodes=5, x_text_feat=[5, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[5], val_mask=[5], test_mask=[5], n_id=[5], e_id=[4], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])],\n",
       "  2: [Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]),\n",
       "   Data(x=[2, 384], edge_index=[2, 1], y=[2], label_names=[7], num_nodes=2, x_text_feat=[2, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2], val_mask=[2], test_mask=[2], n_id=[2], e_id=[1], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])],\n",
       "  0: [Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]),\n",
       "   Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "\n",
    "def getitem(index):\n",
    "    if isinstance(index, list):\n",
    "        return [getitem(i) for i in index]\n",
    "    elif isinstance(index, dict):\n",
    "        return {key: getitem(value) for key, value in index.items()}\n",
    "    elif not isinstance(index, int):\n",
    "        raise IndexError(\"Only integers, lists and dictionaries can be used as indices\")\n",
    "\n",
    "    loader = NeighborLoader(data=cora,\n",
    "                            num_neighbors=args[\"num_neighbors\"],\n",
    "                            input_nodes=torch.LongTensor([index]),\n",
    "                            subgraph_type=args[\"subgraph_type\"])\n",
    "    subgraph = next(iter(loader))\n",
    "    subgraph.batch_size = None\n",
    "\n",
    "    return subgraph\n",
    "\n",
    "batch = getitem(batch1)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_task(task):\n",
    "    label_map = list(task) # Looks like this: (0, 'task1'), (1, 'task2'), ...\n",
    "    label_map_reverse = {v: i for i, v in enumerate(label_map)} # ((0, 'task1'), 0), ((1, 'task2'), 1), ...\n",
    "    all_graphs = []\n",
    "    labels = []\n",
    "    query_mask = []\n",
    "    for label, graphs in task.items():\n",
    "        augmented = [graph for graph in graphs]\n",
    "        all_graphs.extend(augmented)\n",
    "        query_mask.extend([False] * (args[\"n_shot\"]))\n",
    "        query_mask.extend([True] * (args[\"n_query\"]))\n",
    "        labels.extend([label_map_reverse[label]] * len(augmented)) # label_map_reverse[label] is the index of label in label_map\n",
    "    return all_graphs, torch.tensor(labels), torch.tensor(query_mask), label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphs =  [[Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[4, 384], edge_index=[2, 3], y=[4], label_names=[7], num_nodes=4, x_text_feat=[4, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[4], val_mask=[4], test_mask=[4], n_id=[4], e_id=[3], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[5, 384], edge_index=[2, 4], y=[5], label_names=[7], num_nodes=5, x_text_feat=[5, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[5], val_mask=[5], test_mask=[5], n_id=[5], e_id=[4], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[2, 384], edge_index=[2, 1], y=[2], label_names=[7], num_nodes=2, x_text_feat=[2, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2], val_mask=[2], test_mask=[2], n_id=[2], e_id=[1], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[4, 384], edge_index=[2, 3], y=[4], label_names=[7], num_nodes=4, x_text_feat=[4, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[4], val_mask=[4], test_mask=[4], n_id=[4], e_id=[3], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])], [Data(x=[4, 384], edge_index=[2, 3], y=[4], label_names=[7], num_nodes=4, x_text_feat=[4, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[4], val_mask=[4], test_mask=[4], n_id=[4], e_id=[3], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[5, 384], edge_index=[2, 4], y=[5], label_names=[7], num_nodes=5, x_text_feat=[5, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[5], val_mask=[5], test_mask=[5], n_id=[5], e_id=[4], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[2, 384], edge_index=[2, 1], y=[2], label_names=[7], num_nodes=2, x_text_feat=[2, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2], val_mask=[2], test_mask=[2], n_id=[2], e_id=[1], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]), Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1])]]\n",
      "labels =  [tensor([0, 0, 1, 1, 2, 2]), tensor([0, 0, 1, 1, 2, 2])]\n",
      "query_mask =  [tensor([False,  True, False,  True, False,  True]), tensor([False,  True, False,  True, False,  True])]\n",
      "label_map =  [[3, 6, 0], [3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "graphs, labels, query_mask, label_map = map(list, zip(*[process_one_task(task) for task in batch]))\n",
    "print(\"graphs = \", graphs)\n",
    "print(\"labels = \", labels)\n",
    "print(\"query_mask = \", query_mask)\n",
    "print(\"label_map = \", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[3, 384], edge_index=[2, 2], y=[3], label_names=[7], num_nodes=3, x_text_feat=[3, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[3], val_mask=[3], test_mask=[3], n_id=[3], e_id=[2], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]),\n",
       " Data(x=[4, 384], edge_index=[2, 3], y=[4], label_names=[7], num_nodes=4, x_text_feat=[4, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[4], val_mask=[4], test_mask=[4], n_id=[4], e_id=[3], num_sampled_nodes=[2], num_sampled_edges=[1], input_id=[1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1, g2 = graphs[0][0], graphs[0][1]\n",
    "g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[7, 384], edge_index=[2, 5], y=[7], label_names=[2], num_nodes=7, x_text_feat=[7, 768], label_text_feat=[14, 768], edge_text_feat=[2, 768], prompt_text_edge_feat=[2, 768], prompt_text_feat=[2, 768], prompt_edge_feat=[2, 768], edge_label_feat=[4, 768], train_mask=[7], val_mask=[7], test_mask=[7], n_id=[7], e_id=[5], num_sampled_nodes=[2], num_sampled_edges=[2], input_id=[2], batch=[7], ptr=[3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "gg = Batch.from_data_list([g1, g2])\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_task =  2\n",
      "task_len =  6\n",
      "num_labels =  3\n",
      "graphs =  DataBatch(x=[41, 384], edge_index=[2, 29], y=[41], label_names=[12], num_nodes=41, x_text_feat=[41, 768], label_text_feat=[84, 768], edge_text_feat=[12, 768], prompt_text_edge_feat=[12, 768], prompt_text_feat=[12, 768], prompt_edge_feat=[12, 768], edge_label_feat=[24, 768], train_mask=[41], val_mask=[41], test_mask=[41], n_id=[41], e_id=[29], num_sampled_nodes=[12], num_sampled_edges=[12], input_id=[12], batch=[41], ptr=[13])\n",
      "labels =  tensor([0, 0, 1, 1, 2, 2, 0, 0, 1, 1, 2, 2])\n",
      "b_mask =  tensor([[False,  True, False,  True, False,  True],\n",
      "        [False,  True, False,  True, False,  True]])\n",
      "query_mask =  tensor([False,  True, False,  True, False,  True, False,  True, False,  True,\n",
      "        False,  True])\n",
      "label_map =  [3, 6, 0, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "from itertools import chain\n",
    "\n",
    "num_task = len(graphs)\n",
    "task_len = len(graphs[0])\n",
    "num_labels = len(label_map[0])\n",
    "\n",
    "print(\"num_task = \", num_task)\n",
    "print(\"task_len = \", task_len)\n",
    "print(\"num_labels = \", num_labels)\n",
    "\n",
    "graphs = Batch.from_data_list([g for l in graphs for g in l])\n",
    "labels = torch.cat(labels)\n",
    "b_mask = torch.stack(query_mask)\n",
    "query_mask = torch.cat(query_mask)\n",
    "label_map = list(chain(*label_map))\n",
    "\n",
    "print(\"graphs = \", graphs)\n",
    "print(\"labels = \", labels)\n",
    "print(\"b_mask = \", b_mask)\n",
    "print(\"query_mask = \", query_mask)\n",
    "print(\"label_map = \", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2304, 2305, 2306,  ..., 3069, 3070, 3071],\n",
      "        [4608, 4609, 4610,  ..., 5373, 5374, 5375],\n",
      "        [   0,    1,    2,  ...,  765,  766,  767],\n",
      "        [2304, 2305, 2306,  ..., 3069, 3070, 3071],\n",
      "        [1536, 1537, 1538,  ..., 2301, 2302, 2303],\n",
      "        [   0,    1,    2,  ...,  765,  766,  767]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "metagraph_edge_source = torch.arange(labels.size(0)).repeat_interleave(num_labels)\n",
    "\n",
    "metagraph_edge_target = torch.arange(num_labels).repeat(labels.size(0))\n",
    "metagraph_edge_target += (torch.arange(num_task) * num_labels).repeat_interleave(task_len * num_labels) + labels.size(0)\n",
    "\n",
    "metagraph_edge_index = torch.stack([metagraph_edge_source, metagraph_edge_target], dim=0)\n",
    "\n",
    "metagraph_edge_mask = query_mask.repeat_interleave(num_labels)\n",
    "\n",
    "metagraph_edge_attr = torch.nn.functional.one_hot(labels, num_labels).float()\n",
    "metagraph_edge_attr = metagraph_edge_attr.reshape(-1)\n",
    "metagraph_edge_attr = (metagraph_edge_attr * 2 - 1) * (~metagraph_edge_mask)\n",
    "\n",
    "metagraph_edge_attr = torch.stack([metagraph_edge_mask, metagraph_edge_attr], dim=1)\n",
    "\n",
    "label_meta = torch.arange(7 * 768).reshape(7, 768)\n",
    "\n",
    "label_map = torch.tensor(label_map)\n",
    "label_embeddings = label_meta[label_map]\n",
    "print(label_embeddings)\n",
    "\n",
    "labels_onehot = torch.nn.functional.one_hot(labels).float()\n",
    "print(labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SubgraphPygDataset.__init__() got an unexpected keyword argument 'graphnum_neighbors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_pyg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SubgraphPygDataset\n\u001b[0;32m----> 4\u001b[0m custom_subg_cora \u001b[38;5;241m=\u001b[39m \u001b[43mSubgraphPygDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraph_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdirectional\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m d_ldr \u001b[38;5;241m=\u001b[39m DataLoader(custom_subg_cora, batch_sampler\u001b[38;5;241m=\u001b[39mdl\u001b[38;5;241m.\u001b[39mtrn_smplr)\n",
      "\u001b[0;31mTypeError\u001b[0m: SubgraphPygDataset.__init__() got an unexpected keyword argument 'graphnum_neighbors'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils_data.custom_pyg import SubgraphPygDataset\n",
    "\n",
    "custom_subg_cora = SubgraphPygDataset(graph=cora, num_neighbors=[-1], subgraph_type=\"directional\")\n",
    "d_ldr = DataLoader(custom_subg_cora, batch_sampler=dl.trn_smplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 384], edge_index=[2, 10858], y=[2708], label_names=[7], num_nodes=2708, x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
