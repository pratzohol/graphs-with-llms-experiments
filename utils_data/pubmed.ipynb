{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prateek/graphs-with-llms-experiments/utils_data', '/home/prateek/miniconda3/envs/torch_pyg/lib/python310.zip', '/home/prateek/miniconda3/envs/torch_pyg/lib/python3.10', '/home/prateek/miniconda3/envs/torch_pyg/lib/python3.10/lib-dynload', '', '/home/prateek/miniconda3/envs/torch_pyg/lib/python3.10/site-packages', '/home/prateek/graphs-with-llms-experiments']\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch_geometric\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "sys.path.append(osp.abspath(\"..\"))\n",
    "print(sys.path)\n",
    "\n",
    "from utils.encoder import SentenceEncoder\n",
    "from utils_data.custom_pyg import CustomPygDataset\n",
    "from utils.dataloader import GetDataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pubmed dataset\n",
    "data_root = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubmedPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, dataRoot=\"../data\", custom_dataRoot=\"../custom_data\", sentence_encoder=None, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_root = dataRoot\n",
    "        self.custom_data_root = custom_dataRoot\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.custom_data_dir = osp.join(self.custom_data_root, f\"pubmed_{self.sentence_encoder.name}\")\n",
    "\n",
    "        if not osp.exists(self.custom_data_dir):\n",
    "            os.makedirs(self.custom_data_dir)\n",
    "\n",
    "        super().__init__(self.custom_data_dir, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\", \"texts.pkl\"]\n",
    "\n",
    "    def text_to_embed(self, texts):\n",
    "        if self.sentence_encoder is None:\n",
    "            raise NotImplementedError(\"Sentence Encoder is not passed\")\n",
    "        if texts is None:\n",
    "            return None\n",
    "        else:\n",
    "            # returns to self.device\n",
    "            return self.sentence_encoder.encode(texts)\n",
    "\n",
    "    def encode_texts(self, texts):\n",
    "        if isinstance(texts[0], str):\n",
    "            return self.text_to_embed(texts)\n",
    "        return [self.text_to_embed(t) for t in texts]\n",
    "\n",
    "    def generate_custom_data(self):\n",
    "        # Load the raw pubmed dataset\n",
    "        data_path = osp.join(self.data_root, \"pubmed\", \"pubmed.pt\")\n",
    "        raw_pubmed_data = torch.load(data_path)\n",
    "\n",
    "        texts = raw_pubmed_data.raw_text\n",
    "        label_names = raw_pubmed_data.label_names\n",
    "\n",
    "\n",
    "        # Label and label description\n",
    "        category_desc = pd.read_csv(osp.join(self.data_root, \"pubmed\", \"categories.csv\"), sep=\",\", header=None).values\n",
    "\n",
    "        # Sort the label desc by the order of label_names\n",
    "        ordered_desc = []\n",
    "        for i, label in enumerate(label_names):\n",
    "            true_ind = (label == category_desc[:, 0])\n",
    "            ordered_desc.append((label, category_desc[true_ind, 1][0]))\n",
    "\n",
    "        # Prompts for nodes/edges in original graph (can be changed accordingly)\n",
    "        node_texts = [\"Feature Node.\\n Paper Title and abstract: \" + t for t in texts]\n",
    "        edge_text = [\"Feature Edge.\\n Connected papers are cited together by other papers.\"]\n",
    "\n",
    "        # Node classification : Prompts for prompt node and label node (can be changed accordingly)\n",
    "        prompt_node_text = [\"Prompt Node.\\n Node Classification on the paper's category\"]\n",
    "        label_texts = [\"Prompt Node.\\n Literature Category and Description: \" + desc[0] + \" + \" + desc[1] for desc in ordered_desc]\n",
    "\n",
    "        # Link prediction : Prompts for prompt node and edge labels (can be changed accordingly)\n",
    "        prompt_node_edge_text = [\"Prompt Node.\\n Link Prediction on the papers that are cited together\"]\n",
    "        edge_label_text = [\"Prompt Node.\\n Two papers have co-citation\",\n",
    "                           \"Prompt Node.\\n Two papers do not have co-citation\"]\n",
    "\n",
    "        # Prompt for edge b/w prompt node and labels (can be changed accordingly)\n",
    "        prompt_edge_text = [\"Prompt Edge.\"]\n",
    "\n",
    "        return raw_pubmed_data, [node_texts, label_texts, edge_text, prompt_node_edge_text, prompt_node_text, prompt_edge_text, edge_label_text]\n",
    "\n",
    "    def process(self):\n",
    "        # raw pubmed dataset is not in any library, so we process and load it manually in self.generate_custom_data()\n",
    "        pubmed_data_list, texts = self.generate_custom_data()\n",
    "        texts_embed = self.encode_texts(texts)\n",
    "\n",
    "        torch.save(texts, self.processed_paths[1])\n",
    "\n",
    "        pubmed_data_list.num_nodes = pubmed_data_list.y.shape[0]\n",
    "\n",
    "\n",
    "        pubmed_data_list.x_text_feat = texts_embed[0]\n",
    "        pubmed_data_list.label_text_feat = texts_embed[1]\n",
    "        pubmed_data_list.edge_text_feat = texts_embed[2]\n",
    "        pubmed_data_list.prompt_text_edge_feat = texts_embed[3]\n",
    "        pubmed_data_list.prompt_text_feat = texts_embed[4]\n",
    "        pubmed_data_list.prompt_edge_feat = texts_embed[5]\n",
    "        pubmed_data_list.edge_label_feat = texts_embed[6]\n",
    "\n",
    "        pubmed_data_list.train_mask = pubmed_data_list.train_masks[0]\n",
    "        pubmed_data_list.val_mask = pubmed_data_list.val_masks[0]\n",
    "        pubmed_data_list.test_mask = pubmed_data_list.test_masks[0]\n",
    "\n",
    "        pubmed_data_list.train_masks = None\n",
    "        pubmed_data_list.val_masks = None\n",
    "        pubmed_data_list.test_masks = None\n",
    "\n",
    "        # Pass the data_list as a list\n",
    "        data, slices = self.collate([pubmed_data_list])\n",
    "\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        print(\"Pubmed is processed. Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder = SentenceEncoder(\"ST\", root=\"../lang_models\", device=2)\n",
    "custom_pubmed = PubmedPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder2 = SentenceEncoder(\"roberta\", root=\"../lang_models\", device=2)\n",
    "custom_pubmed2 = PubmedPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubmedPyGDataset()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[19717, 384], edge_index=[2, 88670], y=[19717], label_names=[3], category_names=[19717], raw_text=[19717], num_nodes=19717, x_text_feat=[19717, 768], label_text_feat=[3, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[19717], val_mask=[19717], test_mask=[19717])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed = custom_pubmed._data\n",
    "pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x <class 'torch.Tensor'>\n",
      "edge_index <class 'torch.Tensor'>\n",
      "y <class 'torch.Tensor'>\n",
      "label_names <class 'list'>\n",
      "category_names <class 'list'>\n",
      "raw_text <class 'list'>\n",
      "num_nodes <class 'int'>\n",
      "x_text_feat <class 'torch.Tensor'>\n",
      "label_text_feat <class 'torch.Tensor'>\n",
      "edge_text_feat <class 'torch.Tensor'>\n",
      "prompt_text_edge_feat <class 'torch.Tensor'>\n",
      "prompt_text_feat <class 'torch.Tensor'>\n",
      "prompt_edge_feat <class 'torch.Tensor'>\n",
      "edge_label_feat <class 'torch.Tensor'>\n",
      "train_mask <class 'torch.Tensor'>\n",
      "val_mask <class 'torch.Tensor'>\n",
      "test_mask <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for k, v in pubmed:\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pubmed.is_directed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
