{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prateek/graphs-with-llms-experiments/utils_data', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python310.zip', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python3.10', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python3.10/lib-dynload', '', '/home/prateek/miniconda3/envs/torch_pyg_dgl/lib/python3.10/site-packages', '/home/prateek/graphs-with-llms-experiments']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch_geometric\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "sys.path.append(osp.abspath(\"..\"))\n",
    "print(sys.path)\n",
    "\n",
    "from utils.encoder import SentenceEncoder\n",
    "from utils_data.custom_pyg import CustomPygDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the cora dataset\n",
    "data_root = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoraPyGDataset(InMemoryDataset, CustomPygDataset):\n",
    "    def __init__(self, dataRoot=\"../data\", custom_dataRoot=\"../custom_data\", sentence_encoder=None, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_root = dataRoot\n",
    "        self.custom_data_root = custom_dataRoot\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.custom_data_dir = osp.join(self.custom_data_root, f\"cora_{self.sentence_encoder.name}\")\n",
    "\n",
    "        if not osp.exists(self.custom_data_dir):\n",
    "            os.makedirs(self.custom_data_dir)\n",
    "\n",
    "        super().__init__(self.custom_data_dir, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\", \"texts.pkl\"]\n",
    "\n",
    "    def text_to_embed(self, texts):\n",
    "        if self.sentence_encoder is None:\n",
    "            raise NotImplementedError(\"Sentence Encoder is not passed\")\n",
    "        if texts is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.sentence_encoder.encode(texts)  # returns to self.device\n",
    "\n",
    "    def encode_texts(self, texts):\n",
    "        if isinstance(texts[0], str):\n",
    "            return self.text_to_embed(texts)\n",
    "        return [self.text_to_embed(t) for t in texts]\n",
    "\n",
    "    def generate_custom_data(self):\n",
    "        # Load the raw cora dataset\n",
    "        data_path = osp.join(self.data_root, \"cora\", \"cora.pt\")\n",
    "        raw_cora_data = torch.load(data_path)\n",
    "\n",
    "        texts = raw_cora_data.raw_text\n",
    "        label_names = raw_cora_data.label_names\n",
    "\n",
    "\n",
    "        # Label and label description\n",
    "        category_desc = pd.read_csv(osp.join(self.data_root, \"cora\", \"categories.csv\"), sep=\",\").values\n",
    "\n",
    "        # Sort the label desc by the order of label_names\n",
    "        ordered_desc = []\n",
    "        for i, label in enumerate(label_names):\n",
    "            true_ind = (label == category_desc[:, 0])\n",
    "            ordered_desc.append((label, category_desc[true_ind, 1][0]))\n",
    "\n",
    "        # Prompts for nodes/edges in original graph (can be changed accordingly)\n",
    "        node_texts = [\"Feature Node.\\n Paper Title and abstract: \" + t for t in texts]\n",
    "        edge_text = [\"Feature Edge.\\n Connected papers are cited together by other papers.\"]\n",
    "\n",
    "        # Node classification : Prompts for prompt node and label node (can be changed accordingly)\n",
    "        prompt_node_text = [\"Prompt Node.\\n Node Classification on the paper's category\"]\n",
    "        label_texts = [\"Prompt Node.\\n Literature Category and Description: \" + desc[0] + \" + \" + desc[1] for desc in ordered_desc]\n",
    "\n",
    "        # Link prediction : Prompts for prompt node and edge labels (can be changed accordingly)\n",
    "        prompt_node_edge_text = [\"Prompt Node.\\n Link Prediction on the papers that are cited together\"]\n",
    "        edge_label_text = [\"Prompt Node.\\n Two papers have co-citation\",\n",
    "                           \"Prompt Node.\\n Two papers do not have co-citation\"]\n",
    "\n",
    "        # Prompt for edge b/w prompt node and labels (can be changed accordingly)\n",
    "        prompt_edge_text = [\"Prompt Edge.\"]\n",
    "\n",
    "        return raw_cora_data, [node_texts, label_texts, edge_text, prompt_node_edge_text, prompt_node_text, prompt_edge_text, edge_label_text]\n",
    "\n",
    "    def process(self):\n",
    "        # raw cora dataset is not in any library, so we process and load it manually in self.generate_custom_data()\n",
    "        cora_data_list, texts = self.generate_custom_data()\n",
    "        texts_embed = self.encode_texts(texts)\n",
    "\n",
    "        torch.save(texts, self.processed_paths[1])\n",
    "\n",
    "        cora_data_list.x_text_feat = texts_embed[0]\n",
    "        cora_data_list.label_text_feat = texts_embed[1]\n",
    "        cora_data_list.edge_text_feat = texts_embed[2]\n",
    "        cora_data_list.prompt_text_edge_feat = texts_embed[3]\n",
    "        cora_data_list.prompt_text_feat = texts_embed[4]\n",
    "        cora_data_list.prompt_edge_feat = texts_embed[5]\n",
    "        cora_data_list.edge_label_feat = texts_embed[6]\n",
    "\n",
    "        cora_data_list.train_mask = cora_data_list.train_masks[0]\n",
    "        cora_data_list.val_mask = cora_data_list.val_masks[0]\n",
    "        cora_data_list.test_mask = cora_data_list.test_masks[0]\n",
    "\n",
    "        cora_data_list.train_masks = None\n",
    "        cora_data_list.val_masks = None\n",
    "        cora_data_list.test_masks = None\n",
    "\n",
    "        # Pass the data_list as a list\n",
    "        data, slices = self.collate([cora_data_list])\n",
    "\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        print(\"Cora is processed. Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder = SentenceEncoder(\"ST\", root=\"../lang_models\", device=2)\n",
    "custom_cora = CoraPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMencoder2 = SentenceEncoder(\"roberta\", root=\"../lang_models\", device=2)\n",
    "custom_cora2 = CoraPyGDataset(dataRoot=data_root, sentence_encoder=LMencoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(raw_text=[2708], y=[2708], label_names=[7], edge_index=[2, 10858], x=[2708, 384], category_names=[2708], x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora = custom_cora._data\n",
    "cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(raw_text=[2708], y=[2708], label_names=[7], edge_index=[2, 10858], x=[2708, 384], category_names=[2708], x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cora._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(raw_text=[1], y=[2708], label_names=[1], edge_index=[2, 10858], x=[2708, 384], category_names=[1], x_text_feat=[2708, 768], label_text_feat=[7, 768], edge_text_feat=[1, 768], prompt_text_edge_feat=[1, 768], prompt_text_feat=[1, 768], prompt_edge_feat=[1, 768], edge_label_feat=[2, 768], train_mask=[2708], val_mask=[2708], test_mask=[2708], batch=[2708], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dl = DataLoader(custom_cora, batch_size=12)\n",
    "\n",
    "for batch in dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(custom_cora, CustomPygDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoraPyGDataset()\n"
     ]
    }
   ],
   "source": [
    "def f(var : CustomPygDataset):\n",
    "    print(var)\n",
    "\n",
    "f(custom_cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2,  ..., 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = cora.y.squeeze()\n",
    "print(label)\n",
    "label.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cora.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -2, -3,  ...,  1,  1,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora.y[cora.train_mask] = -1 - cora.y[cora.train_mask]\n",
    "cora.y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
